# LLM 后端配置
# LangChain 1.0 + OpenRouter

backend: "langchain"  # 使用 LangChain 1.0 (已迁移,移除 LiteLLM)

# ========================================
# LangChain 配置 (当前使用)
# ========================================
langchain:
  model: "deepseek/deepseek-v3.1-terminus"  # OpenRouter 模型 ID
  temperature: 0.7
  max_tokens: 4096
  streaming: true

# ========================================
# 支持的模型 (通过 OpenRouter)
# ========================================
# - deepseek/deepseek-v3.1-terminus (默认,高性价比)
# - anthropic/claude-3.5-sonnet (高质量推理)
# - anthropic/claude-3-haiku (快速任务)
# - openai/gpt-4-turbo (备用)
# - qwen/qwen-2.5-72b-instruct (中文优化)

# ========================================
# 环境变量要求
# ========================================
# OPENROUTER_API_KEY=your_key_here
# OPENROUTER_BASE_URL=https://openrouter.ai/api/v1 (可选)
# DEFAULT_MODEL=deepseek/deepseek-v3.1-terminus (可选)

# ========================================
# 性能说明
# ========================================
# deepseek/deepseek-v3.1-terminus: ~$0.001/回合,中文优秀
# claude-3.5-sonnet: ~$0.015/回合,英文最佳
# qwen-2.5: ~$0.002/回合,中文优化

# ========================================
# 注意
# ========================================
# LiteLLM 已被移除,请使用 LangChain 1.0
# 架构: LangChain → OpenRouter → Models
