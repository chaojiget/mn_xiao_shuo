# ä¸‹ä¸€æ­¥è¡ŒåŠ¨æŒ‡å— ğŸš€

## ç°åœ¨å°±åš (5-10åˆ†é’Ÿ)

### 1ï¸âƒ£ é…ç½®å¼€å‘ç¯å¢ƒ

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd /Users/lijianyong/mn_xiao_shuo

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source venv/bin/activate

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# é…ç½®ç¯å¢ƒå˜é‡
cp .env.example .env

# ç¼–è¾‘ .env,å¡«å…¥ä½ çš„ Anthropic API key
# ä½¿ç”¨ä½ å–œæ¬¢çš„ç¼–è¾‘å™¨,ä¾‹å¦‚:
# nano .env
# æˆ– vim .env
# æˆ– code .env (VS Code)
```

åœ¨ `.env` ä¸­è®¾ç½®:
```
ANTHROPIC_API_KEY=sk-ant-xxx...  # ä½ çš„çœŸå® API key
```

### 2ï¸âƒ£ éªŒè¯ç¯å¢ƒ

```bash
# è¿è¡Œç¯å¢ƒæµ‹è¯•è„šæœ¬
python test_setup.py
```

å¦‚æœæ‰€æœ‰æµ‹è¯•é€šè¿‡,ä½ å°±å¯ä»¥å¼€å§‹å¼€å‘äº†! ğŸ‰

---

## ä»Šå¤©å¯ä»¥å¼€å§‹çš„å¼€å‘ä»»åŠ¡

### é€‰é¡¹ A: å¿«é€ŸåŸå‹(æ¨èæ–°æ‰‹)

åˆ›å»ºä¸€ä¸ªæœ€ç®€å•çš„å°è¯´ç”Ÿæˆå™¨,éªŒè¯æ•´ä½“æµç¨‹:

**åˆ›å»º `minimal_generator.py`:**

```python
"""æœ€ç®€å•çš„å°è¯´ç”Ÿæˆå™¨ - éªŒè¯æ¦‚å¿µ"""

import asyncio
import json
from dotenv import load_dotenv
from src.llm import LiteLLMClient

load_dotenv()

async def generate_chapter(client, setting, chapter_num):
    """ç”Ÿæˆä¸€ç« """
    prompt = f"""
ä½ æ˜¯ä¸€ä¸ªç§‘å¹»å°è¯´ä½œå®¶ã€‚

è®¾å®š:
{setting["setting_text"]}

ä¸»è§’: {setting["ä¸»è§’è®¾å®š"]["å§“å"]}

ä»»åŠ¡: å†™ç¬¬ {chapter_num} ç« çš„å†…å®¹(800å­—å·¦å³)ã€‚

è¦æ±‚:
1. ç¬¦åˆè®¾å®šä¸­çš„ç¡¬è§„åˆ™
2. æ¨è¿›å‰§æƒ…
3. æœ‰å…·ä½“çš„åœºæ™¯æå†™
4. åŒ…å«å¯¹è¯
"""

    result = await client.generate(
        prompt=prompt,
        model="claude-sonnet",
        max_tokens=2000,
        temperature=0.8
    )

    return result

async def main():
    # åŠ è½½è®¾å®š
    with open("examples/scifi_setting.json", "r", encoding="utf-8") as f:
        setting = json.load(f)

    # åˆ›å»º LLM å®¢æˆ·ç«¯
    client = LiteLLMClient()

    print("=" * 60)
    print(f"å¼€å§‹ç”Ÿæˆå°è¯´: {setting['title']}")
    print("=" * 60)

    # ç”Ÿæˆ 3 ç« 
    for i in range(1, 4):
        print(f"\næ­£åœ¨ç”Ÿæˆç¬¬ {i} ç« ...")
        chapter = await generate_chapter(client, setting, i)

        print(f"\n{'=' * 60}")
        print(f"ç¬¬ {i} ç« ")
        print("=" * 60)
        print(chapter)

        # ä¿å­˜
        with open(f"chapter_{i}.txt", "w", encoding="utf-8") as f:
            f.write(chapter)

        print(f"\nâœ… ç¬¬ {i} ç« å·²ä¿å­˜åˆ° chapter_{i}.txt")

if __name__ == "__main__":
    asyncio.run(main())
```

**è¿è¡Œ:**
```bash
python minimal_generator.py
```

è¿™ä¸ªç®€å•ç‰ˆæœ¬å¯ä»¥å¸®ä½ :
- âœ… éªŒè¯ LLM é›†æˆå·¥ä½œæ­£å¸¸
- âœ… ç†è§£æç¤ºè¯å·¥ç¨‹çš„é‡è¦æ€§
- âœ… çœ‹åˆ°åˆæ­¥çš„ç”Ÿæˆæ•ˆæœ
- âœ… ä¸ºåç»­å¼€å‘å»ºç«‹ä¿¡å¿ƒ

### é€‰é¡¹ B: å®ç° Global Director (æ¨èæœ‰ç»éªŒçš„å¼€å‘è€…)

æŒ‰ç…§ `CHECKLIST.md` ç¬¬ 1 å‘¨çš„ä»»åŠ¡:

**1. åˆ›å»º Global Director æ¡†æ¶**

```bash
# åˆ›å»ºç›®å½•
mkdir -p src/director

# åˆ›å»ºæ–‡ä»¶
touch src/director/__init__.py
touch src/director/gd.py
touch src/director/scoring.py
```

**2. åœ¨ `src/director/gd.py` ä¸­å®ç°åŸºç¡€æ¡†æ¶:**

```python
"""Global Director - å…¨å±€å¯¼æ¼”æ ¸å¿ƒé€»è¾‘"""

from typing import List, Dict, Optional
from enum import Enum

from ..models import WorldState, EventNode, EventArc, ActionQueue
from ..llm import LiteLLMClient


class NovelType(Enum):
    SCIFI = "scifi"
    XIANXIA = "xianxia"


class Preference(Enum):
    PLAYABILITY = "playability"
    NARRATIVE = "narrative"
    HYBRID = "hybrid"


class GlobalDirector:
    """å…¨å±€å¯¼æ¼” - ç³»ç»Ÿæ ¸å¿ƒè°ƒåº¦å™¨"""

    def __init__(
        self,
        setting: Dict,
        novel_type: NovelType,
        preference: Preference
    ):
        self.setting = setting
        self.novel_type = novel_type
        self.preference = preference

        # åˆå§‹åŒ–çŠ¶æ€
        self.world_state = self._init_world_state()
        self.event_arcs = self._init_event_arcs()
        self.completed_events = []
        self.stall_rounds = 0

        # LLM å®¢æˆ·ç«¯
        self.llm_client = LiteLLMClient()

    def _init_world_state(self) -> WorldState:
        """ä»è®¾å®šåˆå§‹åŒ–ä¸–ç•ŒçŠ¶æ€"""
        # TODO: å®ç°è®¾å®šè§£æ
        return WorldState(timestamp=0, turn=0)

    def _init_event_arcs(self) -> List[EventArc]:
        """ä»è®¾å®šåˆå§‹åŒ–äº‹ä»¶çº¿"""
        # TODO: å®ç°äº‹ä»¶çº¿ç”Ÿæˆ
        return []

    async def run_scene_loop(self):
        """åœºæ™¯å¾ªç¯ä¸»é€»è¾‘"""
        while not self.is_story_complete():
            # 1. è¯„åˆ†å¹¶é€‰æ‹©ä¸‹ä¸€ä¸ªäº‹ä»¶
            next_event = await self.score_and_select_event()

            if next_event is None:
                print("æ²¡æœ‰å¯ç”¨äº‹ä»¶,æ•…äº‹ç»“æŸã€‚")
                break

            # 2. ç”ŸæˆåŠ¨ä½œé˜Ÿåˆ—
            action_queue = await self.generate_action_queue(next_event)

            # 3. æ‰§è¡ŒåŠ¨ä½œ
            result = await self.execute_actions(action_queue)

            # 4. ä¸€è‡´æ€§å®¡è®¡(TODO)

            # 5. æ›´æ–°çŠ¶æ€(TODO)

            # 6. è®°å½•å®Œæˆçš„äº‹ä»¶
            self.completed_events.append(next_event.id)

            yield result

    def is_story_complete(self) -> bool:
        """æ£€æŸ¥æ•…äº‹æ˜¯å¦å®Œæˆ"""
        # ç®€å•å®ç°: æ‰€æœ‰äº‹ä»¶éƒ½å®Œæˆ
        return len(self.completed_events) >= 10  # æš‚å®š 10 ä¸ªäº‹ä»¶

    async def score_and_select_event(self) -> Optional[EventNode]:
        """è¯„åˆ†å¹¶é€‰æ‹©ä¸‹ä¸€ä¸ªäº‹ä»¶"""
        # TODO: å®ç°è¯„åˆ†é€»è¾‘
        # ç°åœ¨è¿”å›ç¬¬ä¸€ä¸ªå¯ç”¨äº‹ä»¶
        for arc in self.event_arcs:
            event = arc.get_next_event(self.world_state, self.completed_events)
            if event:
                return event
        return None

    async def generate_action_queue(self, event: EventNode) -> ActionQueue:
        """ç”ŸæˆåŠ¨ä½œé˜Ÿåˆ—"""
        # TODO: ä½¿ç”¨ LLM ç”Ÿæˆè¯¦ç»†åŠ¨ä½œ
        return ActionQueue(
            event_id=event.id,
            goal=event.goal
        )

    async def execute_actions(self, queue: ActionQueue) -> Dict:
        """æ‰§è¡ŒåŠ¨ä½œé˜Ÿåˆ—"""
        # TODO: å®ç°å®Œæ•´çš„åŠ¨ä½œæ‰§è¡Œ
        # ç°åœ¨ç®€å•ç”Ÿæˆåœºæ™¯
        prompt = f"ä¸ºå°è¯´ç”Ÿæˆä¸€ä¸ªåœºæ™¯,ç›®æ ‡: {queue.goal}"

        content = await self.llm_client.generate(
            prompt=prompt,
            model="claude-sonnet",
            max_tokens=1000
        )

        return {
            "event_id": queue.event_id,
            "content": content,
            "success": True
        }
```

**3. æµ‹è¯•åŸºç¡€æ¡†æ¶:**

```python
# test_gd.py

import asyncio
from src.director.gd import GlobalDirector, NovelType, Preference

async def test():
    setting = {"title": "æµ‹è¯•å°è¯´"}

    director = GlobalDirector(
        setting=setting,
        novel_type=NovelType.SCIFI,
        preference=Preference.HYBRID
    )

    async for scene in director.run_scene_loop():
        print(scene)

if __name__ == "__main__":
    asyncio.run(test())
```

---

## æœ¬å‘¨ç›®æ ‡

### ğŸ¯ Week 1 ç›®æ ‡: èƒ½ç”Ÿæˆç®€å•çš„å°è¯´ç« èŠ‚

**Day 1-2**: å®ç° Global Director åŸºç¡€æ¡†æ¶
**Day 3-4**: å®ç°è¯„åˆ†ç³»ç»Ÿ
**Day 5-6**: å®Œå–„åŠ¨ä½œç”Ÿæˆå’Œæ‰§è¡Œ
**Day 7**: ç«¯åˆ°ç«¯æµ‹è¯•

**æˆåŠŸæ ‡å‡†**:
- âœ… èƒ½ä» JSON è®¾å®šå¯åŠ¨ç³»ç»Ÿ
- âœ… èƒ½ç”Ÿæˆè¿è´¯çš„ 3-5 ä¸ªåœºæ™¯
- âœ… è¯„åˆ†ç³»ç»Ÿèƒ½é€‰æ‹©åˆé€‚çš„äº‹ä»¶
- âœ… ä»£ç æœ‰åŸºç¡€çš„å•å…ƒæµ‹è¯•

---

## å¼€å‘å»ºè®®

### ğŸ’¡ æç¤ºè¯å·¥ç¨‹æŠ€å·§

ç”Ÿæˆé«˜è´¨é‡å°è¯´å†…å®¹çš„å…³é”®åœ¨äºæç¤ºè¯è®¾è®¡:

**å¥½çš„æç¤ºè¯ç»“æ„:**
```
ä½ æ˜¯ä¸€ä¸ª{å°è¯´ç±»å‹}ä½œå®¶ã€‚

ã€ä¸–ç•Œè®¾å®šã€‘
{è¯¦ç»†è®¾å®š}

ã€å½“å‰çŠ¶æ€ã€‘
- æ—¶é—´: {timestamp}
- åœ°ç‚¹: {location}
- ä¸»è§’çŠ¶æ€: {character_state}

ã€å‰æƒ…æè¦ã€‘
{previous_events_summary}

ã€æœ¬ç« ç›®æ ‡ã€‘
{chapter_goal}

ã€çº¦æŸæ¡ä»¶ã€‘
1. å¿…é¡»éµå®ˆ: {hard_rules}
2. é¿å…: {forbidden_actions}
3. æ¨è¿›: {clues_to_advance}

ã€è¾“å‡ºè¦æ±‚ã€‘
1. å­—æ•°: 800-1200å­—
2. åŒ…å«å…·ä½“åœºæ™¯æå†™
3. æ¨è¿›å‰§æƒ…
4. ç¬¦åˆäººç‰©æ€§æ ¼
5. åŸ‹ä¸‹ä¼ç¬”: {setups}

è¯·å¼€å§‹åˆ›ä½œ:
```

### ğŸ› è°ƒè¯•æŠ€å·§

1. **å¯ç”¨è¯¦ç»†æ—¥å¿—**
```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

2. **ä¿å­˜ä¸­é—´ç»“æœ**
```python
# ä¿å­˜æ¯æ¬¡ LLM è°ƒç”¨çš„ç»“æœ
with open(f"debug/prompt_{i}.txt", "w") as f:
    f.write(prompt)

with open(f"debug/response_{i}.txt", "w") as f:
    f.write(response)
```

3. **ä½¿ç”¨æ›´ä¾¿å®œçš„æ¨¡å‹æµ‹è¯•**
```python
# å¼€å‘æ—¶ç”¨ Haiku
result = await client.generate(
    ...,
    model="claude-haiku"  # ä¾¿å®œ 10 å€
)
```

### ğŸ“š å‚è€ƒèµ„æ–™

- **MCP æ–‡æ¡£**: https://modelcontextprotocol.io/
- **LiteLLM æ–‡æ¡£**: https://docs.litellm.ai/
- **Anthropic API æ–‡æ¡£**: https://docs.anthropic.com/
- **æœ¬é¡¹ç›®æ¶æ„**: `ARCHITECTURE.md`
- **å®æ–½æŒ‡å—**: `IMPLEMENTATION_GUIDE.md`

---

## é‡åˆ°é—®é¢˜?

### å¸¸è§é—®é¢˜å¿«é€Ÿè§£å†³

**é—®é¢˜ 1: `ModuleNotFoundError: No module named 'xxx'`**
```bash
pip install xxx
# æˆ–
pip install -r requirements.txt
```

**é—®é¢˜ 2: `litellm.exceptions.AuthenticationError`**
- æ£€æŸ¥ `.env` ä¸­çš„ API key æ˜¯å¦æ­£ç¡®
- ç¡®ä¿ API key æœ‰è¶³å¤Ÿçš„é¢åº¦

**é—®é¢˜ 3: ç”Ÿæˆå†…å®¹è´¨é‡ä¸å¥½**
- è°ƒæ•´æç¤ºè¯,å¢åŠ æ›´å¤šä¸Šä¸‹æ–‡
- æé«˜ temperature (0.7 â†’ 0.9)
- ä½¿ç”¨æ›´å¼ºçš„æ¨¡å‹(haiku â†’ sonnet)

**é—®é¢˜ 4: é€Ÿåº¦å¤ªæ…¢**
- å‡å°‘ max_tokens
- ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹(sonnet â†’ haiku)
- å¹¶å‘ç”Ÿæˆç‹¬ç«‹å†…å®¹

### è·å–å¸®åŠ©

1. æŸ¥çœ‹é¡¹ç›®æ–‡æ¡£(`ARCHITECTURE.md`, `IMPLEMENTATION_GUIDE.md`)
2. æ£€æŸ¥ä»£ç æ³¨é‡Šå’Œ docstrings
3. è¿è¡Œ `python test_setup.py` è¯Šæ–­ç¯å¢ƒé—®é¢˜

---

## ğŸ‰ å¼€å§‹ä½ çš„å¼€å‘ä¹‹æ—…!

ä½ ç°åœ¨æ‹¥æœ‰:
- âœ… å®Œæ•´çš„é¡¹ç›®æ¶æ„
- âœ… æ¸…æ™°çš„å¼€å‘è·¯çº¿å›¾
- âœ… å¯è¿è¡Œçš„ä»£ç æ¨¡æ¿
- âœ… è¯¦ç»†çš„æ–‡æ¡£å’ŒæŒ‡å—

**ç«‹å³è¡ŒåŠ¨:**

1. é…ç½®ç¯å¢ƒ (5åˆ†é’Ÿ)
2. è¿è¡Œ test_setup.py (1åˆ†é’Ÿ)
3. é€‰æ‹©å¼€å‘è·¯å¾„ (é€‰é¡¹Aæˆ–B)
4. å¼€å§‹ç¼–ç ! ğŸš€

è®°ä½: **å…ˆè®©å®ƒå·¥ä½œ,å†è®©å®ƒä¼˜é›…,æœ€åè®©å®ƒå¿«é€Ÿ**

ç¥ä½ å¼€å‘é¡ºåˆ©! å¦‚æœ‰é—®é¢˜,å‚è€ƒæ–‡æ¡£æˆ–è°ƒè¯•è¾“å‡ºã€‚

---

**é¡¹ç›®åˆ›å»º**: 2025-10-30
**ä¸‹æ¬¡æ›´æ–°**: å®Œæˆ Week 1 ä»»åŠ¡å
