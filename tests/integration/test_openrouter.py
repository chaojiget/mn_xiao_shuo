#!/usr/bin/env python3
"""
æµ‹è¯• OpenRouter é›†æˆ
"""

import asyncio
import os
import sys
from pathlib import Path
from dotenv import load_dotenv

# æ·»åŠ  src åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

load_dotenv()


async def test_openrouter():
    """æµ‹è¯• OpenRouter é›†æˆ"""
    from src.llm import LiteLLMClient

    print("=" * 60)
    print("æµ‹è¯• OpenRouter é›†æˆ")
    print("=" * 60)

    # æ£€æŸ¥ API key
    api_key = os.getenv("OPENROUTER_API_KEY")
    if not api_key or api_key.startswith("your_"):
        print("âŒ è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½® OPENROUTER_API_KEY")
        return False

    print(f"âœ… API Key å·²é…ç½® (å‰10ä½: {api_key[:10]}...)")

    try:
        # åˆ›å»ºå®¢æˆ·ç«¯
        client = LiteLLMClient()
        print("âœ… LiteLLM å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")

        # åˆ—å‡ºå¯ç”¨æ¨¡å‹
        models = client.list_models()
        print(f"\nå¯ç”¨æ¨¡å‹ ({len(models)} ä¸ª):")
        for model in models:
            print(f"  - {model}")

        # æµ‹è¯•å„ä¸ªæ¨¡å‹
        test_prompts = {
            "claude-sonnet": "ç”¨ä¸€å¥è¯ä»‹ç»ç§‘å¹»å°è¯´çš„é­…åŠ›ã€‚",
            "deepseek": "ç”¨ä¸€å¥è¯ä»‹ç»ç„å¹»å°è¯´çš„ç‰¹ç‚¹ã€‚",
            "qwen": "ç”¨ä¸€å¥è¯è¯´æ˜ä»€ä¹ˆæ˜¯å…¨å±€å¯¼æ¼”ç³»ç»Ÿã€‚",
        }

        print("\n" + "=" * 60)
        print("æµ‹è¯•æ¨¡å‹ç”Ÿæˆ")
        print("=" * 60)

        for model_name, prompt in test_prompts.items():
            try:
                print(f"\nğŸ”„ æµ‹è¯•æ¨¡å‹: {model_name}")
                print(f"æç¤º: {prompt}")

                result = await client.generate(
                    prompt=prompt,
                    model=model_name,
                    max_tokens=150,
                    temperature=0.7
                )

                print(f"âœ… ç”ŸæˆæˆåŠŸ:")
                print(f"   {result}\n")

            except Exception as e:
                print(f"âŒ æ¨¡å‹ {model_name} æµ‹è¯•å¤±è´¥: {e}\n")

        return True

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_structured_output():
    """æµ‹è¯•ç»“æ„åŒ–è¾“å‡º"""
    from src.llm import LiteLLMClient

    print("\n" + "=" * 60)
    print("æµ‹è¯•ç»“æ„åŒ–è¾“å‡º (JSON Schema)")
    print("=" * 60)

    client = LiteLLMClient()

    schema = {
        "type": "object",
        "properties": {
            "title": {"type": "string", "description": "å°è¯´æ ‡é¢˜"},
            "genre": {"type": "string", "description": "ç±»å‹(ç§‘å¹»/ç„å¹»)"},
            "protagonist": {"type": "string", "description": "ä¸»è§’åå­—"},
            "setting": {"type": "string", "description": "èƒŒæ™¯è®¾å®š,ä¸€å¥è¯"}
        },
        "required": ["title", "genre", "protagonist", "setting"]
    }

    prompt = "åˆ›å»ºä¸€ä¸ªç§‘å¹»å°è¯´çš„åŸºæœ¬è®¾å®š"

    try:
        result = await client.generate_structured(
            prompt=prompt,
            schema=schema,
            model="deepseek",  # ä½¿ç”¨ä¾¿å®œçš„æ¨¡å‹æµ‹è¯•
            max_tokens=300
        )

        print("âœ… ç»“æ„åŒ–è¾“å‡ºæˆåŠŸ:")
        import json
        print(json.dumps(result, indent=2, ensure_ascii=False))

        return True

    except Exception as e:
        print(f"âŒ ç»“æ„åŒ–è¾“å‡ºæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_batch_generation():
    """æµ‹è¯•æ‰¹é‡ç”Ÿæˆ"""
    from src.llm import LiteLLMClient

    print("\n" + "=" * 60)
    print("æµ‹è¯•æ‰¹é‡ç”Ÿæˆ")
    print("=" * 60)

    client = LiteLLMClient()

    prompts = [
        "ç”¨10å­—æè¿°ç§‘å¹»å°è¯´ã€‚",
        "ç”¨10å­—æè¿°ç„å¹»å°è¯´ã€‚",
        "ç”¨10å­—æè¿°æ‚¬ç–‘å°è¯´ã€‚",
    ]

    try:
        results = await client.batch_generate(
            prompts=prompts,
            model="qwen",  # ä½¿ç”¨ä¾¿å®œå¿«é€Ÿçš„æ¨¡å‹
            max_tokens=50
        )

        print("âœ… æ‰¹é‡ç”ŸæˆæˆåŠŸ:")
        for i, result in enumerate(results, 1):
            print(f"  {i}. {result}")

        return True

    except Exception as e:
        print(f"âŒ æ‰¹é‡ç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\n" + "=" * 60)
    print(" OpenRouter + LiteLLM é›†æˆæµ‹è¯•")
    print("=" * 60)

    results = {
        "åŸºç¡€é›†æˆ": await test_openrouter(),
        "ç»“æ„åŒ–è¾“å‡º": await test_structured_output(),
        "æ‰¹é‡ç”Ÿæˆ": await test_batch_generation(),
    }

    # æ€»ç»“
    print("\n" + "=" * 60)
    print(" æµ‹è¯•æ€»ç»“")
    print("=" * 60)

    for name, result in results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{name}: {status}")

    all_passed = all(results.values())

    print("\n" + "=" * 60)
    if all_passed:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! OpenRouter é›†æˆæˆåŠŸã€‚")
        print("\nâœ¨ ä½ ç°åœ¨å¯ä»¥:")
        print("1. ä½¿ç”¨ Claude Sonnet 4.5 ç”Ÿæˆé«˜è´¨é‡å†…å®¹")
        print("2. ä½¿ç”¨ DeepSeek/Qwen èŠ‚çœæˆæœ¬ (ä¾¿å®œ10å€+)")
        print("3. è‡ªåŠ¨é™çº§å’Œé‡è¯•æœºåˆ¶")
        print("\nä¸‹ä¸€æ­¥: å¼€å§‹å®ç° Global Director!")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥,è¯·æ£€æŸ¥:")
        print("1. .env æ–‡ä»¶ä¸­çš„ OPENROUTER_API_KEY æ˜¯å¦æ­£ç¡®")
        print("2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        print("3. OpenRouter è´¦æˆ·æ˜¯å¦æœ‰ä½™é¢")

    print("=" * 60)


if __name__ == "__main__":
    asyncio.run(main())
